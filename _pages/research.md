---
layout: page
permalink: /research/
title: research
description: Summary of my research
nav: true
nav_order: 2
---

**My guiding research objective is to understand the organizational communication that enables the development of safe and responsible technologies.**

My dissertation project, *Ethical Sensemaking in the AI Assemblage,* examines how AI developers engage in collective sensemaking processes to co-construct ethics in AI systems. 

I also study how technology-related trends are communicatively enacted in work contexts. I have contributed to projects theorizing the role of online communication as an occupational backstage in the absence of co-located organizing spaces for workers in the gig economy, and am currently working on examining risk and safety related discourses among gig workers in these online spaces. I have also studied membership negotiation processes among contractors and impression management discourses in response to mass layoffs in the tech industry.

**Lab & Grant Work** 

Since 2022, I’ve managed the [Virtual Identity, Community, and Entitativity (V.I.C.E.)](https://pages.charlotte.edu/virtual-communities-lab/supporting-research/) Research Group headed by Dr. Anita Blanchard. The VICE lab is an interdisciplinary research initiative focused on understanding how groups and teams develop and maintain a sense of community and “groupy-ness” in digitally-mediated settings. As the Research Group Manager, I have supported experimental research projects, publishing, and undergraduate research mentorship. 

Our current project, in partnership with Dr. Joe Allen and the [Center for Meeting Effectiveness](https://rmcoeh.com/services/center-for-meeting-effectiveness), seeks to understand how members of distributed scientific and technology research teams maintain group identification and entitativity during and between their virtual meetings. We have been awarded a multi-year grant for this research from the Alfred P. Sloan foundation.  

**Applied Research**  

In 2024, I worked with the UX Research and Education team at Aether - Microsoft’s internal advisory group for AI ethics research and engineering. I led a qualitative research project aimed at understanding employees’ strategies for bottom-up responsible AI advocacy.
